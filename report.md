<div>
<img src='https://github.com/FedorSafonov/computer-vision-for-conveyor-belt/blob/main/report_images/report.png' align="right" height="139" />
</div>

# Проект: Детекция и трекинг мусора на ленте конвейера.

## Введение

* **Описание задачи:**  Необходимо разработать решение для отслеживания и сортировки мусора на конвейере – выделять пластиковые бутылки в общем потоке предметов, которая будет иметь максимально высокую метрику MOTA (Multiple Object Tracking Accuracy).
* **Цель проекта:**  Целью данного проекта является модель, которая выдает координаты центра обнаруженных пластиковых бутылок для каждого кадра для передачи манипулятору. Необходимо учесть, чтобы скорость обработки была не более 100 мс.
* **Датасет:** Предобученная модель детекции пластиковых бутылок и код для ее запуска. Датасет (изображения + разметка) в нескольких форматах: MOT, COCO, CVAT. Примеры видеозаписей работы конвейера.

<div>
<img src='https://github.com/FedorSafonov/computer-vision-for-conveyor-belt/blob/main/report_images/%D0%9A%D0%BE%D0%BD%D0%B2%D0%B5%D0%B9%D0%B5%D1%80.png'/>
</div>
 
## Методы
 При работе над проектом мы выбрали *библиотеку Ultralytics* и *MMDetection*, потому что они обеспечивают встроенную поддержку различных наборов данных, что облегчает начало работы с высококачественными данными (видео) и это сэкономило нам много времени и сил на начальных этапах работы над проектом. 

 * **Аннотирование данных** — это процесс маркировки данных для передачи знаний модели.В нашем проекте мы использовали следующие типы аннотирование данных:
     * **1.Обнаружение объектов (Object detection "box")** - рисуешь ограничительные рамки вокруг каждого объекта на изображении и метишь каждую рамку.
     * **2.Сегментация изображения (Segmentation)** метишь каждый пиксель на изображении в соответствии с объектом, к которому он относится, создав подробные границы объектов, использовали **Fast-SAM** от Meta (запрещённая в РФ).
 
  Аннотирование данных можно проводить в ручную, но это очень долгий и сложный процесс, поэтому мы решили использувать автоматический инструмент - **SAM**, в дальнейшем использовали более современный инструмент - **Annotator**.

   Для сегментации использовали следующие модели **MobileSAM** это легкая и быстрая модель, но ее результат выполнения более 100 мс. Еще использовали модель **Instance с детектором RTMDet-Ins**, обучали на 10 эпохах - результат очень низкий, большое количество ошибок и пропусков объектов.
   
  Для отслеживания нескольких объектов в видео в реальном времени мы использовали *BoT-SORT*(простой и быстрый метод с хорошим компромиссом между точностью и скоростью.) и *ByteTrack*(современный алгоритм трекинга, известный своей высокой производительностью и точностью.), в процессии эксперементов определили лучший трекинг - **BoT-SORT**. 


* **Оценка качества:**  Для оценки качества моделей были использованы следующие метрики:
    * MOTA (Multiple Object Tracking Accuracy)
    * MOTP (Multiple Object Tracking Precision)

## Результаты

* **Таблицы с результатами:**

| Модель+Tracking          | Precision | Recall  | MOTA| MOTP |Time local*|Time Kaggle|Time Google Colab|
|-----------------------------|------------|-----------|-----------|-------------|-----|--------|-------|
| YOLO+BotSORT (обученная заказчиком) | 0.983012| 0.820765| 0.794438| 0.141853 |24|13|11|
| YOLO+ByteTrack (обученная заказчиком) | 0.927311| 0.890224 | 0.748856| 0.586237|53|27|22|



* *Для определения *Time local* использовалось железо:
    * Процессор Intel® Core™ i7-12650H
    * Оперативная память 16Gb RAM
    * Видео-карта RTX 4060 mobile

* **Анализ результатов:**
    * **1YOLO+BotSORT** показала лучший результат, с метрикой **МОТА=0.92**
    * Модель 2YOLO+BotSORT хороша, но по метрике ниже, всего 0.79
    * Обучали модель MMDetection, но улучшений не показала.
    * Модели 2YOLO+ByteTrack по всем показателям хуже выбранной модели, трекинг ByteTrack слаб, его не стои использовать.


## Обсуждение

* **Преимущества и недостатки разных моделей+tracking:**

  * **базовая:**
      * **Преимущества:**  Простота,  быстрота,  небольшие требования к ресурсам.
      * **Недостатки:**  Низкое качество по сравнению с более сложными моделями.
  * **MobileSAM**
      * **Преимущества:** легкая и быстрая модель. 
      * **Недостатки:** лучше подходит для мобильных приложений.
  * **Instance с детектором RTMDet-Ins**
      * **Преимущества:** легко обучается.  
      * **Недостатки:**  большое количество ошибок и пропусков объектов.
  * **2YOLO+ByteTrack**
      * **Преимущества:** скорость, небольшие требования к ресурсам. 
      * **Недостатки:** слабый трекинг ByteTrack. 
  * **1YOLO+BotSORT**
      * **Преимущества:** скорость, качество, метрика. 
      * **Недостатки:**  есть еще куда улучшать качество метрики.

  
## Выводы

* **Выбор модели для отслеживания и сортировка мусора на конвейере:**  
* **Основной вывод:**  В ходе проекта были исследованы различные подходы и использованы различные модели.  Лучший результаты показала *библиотека Ultralytics* с моделью *YOLO* с метрикой **МОТА=0.92**.
  
* **Дальнейшее развитие:**  
   * **Использование других моделей:**  Можно попробовать использовать другие модели,  такие как:
       * Региональные сверточные нейронные сети - **Mask R-CNN**
       * Однократный мультибоксный детектор - **SSD-накопитель**
       * Трансформеры зрения - **Swin Transformer**
       * Эффективная сеть EfficientNet  - **Detectron2**
  
     
## Ссылки
[**Документация Ultralytics**](https://docs.ultralytics.com)

[**Документация MMDetection**](https://mmdetection.readthedocs.io/en/latest/)
<div>
<img src='https://github.com/FedorSafonov/computer-vision-for-conveyor-belt/blob/main/report_images/%D1%88%D1%82%D0%B0%D0%BC%D0%BF.jpg' align="right" height="139" />
</div>

[**Лицензия**](https://github.com/FedorSafonov/computer-vision-for-conveyor-belt/blob/main/LICENSE)
